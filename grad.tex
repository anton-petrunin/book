%%!TEX root = all.tex
%arrays^
\chapter{Gradient curves}%ready

The technique of gradient flow takes it roots in Sharafutdinov's retraction, 
which was introduced in \cite{sharafutdinov} and used  widely in comparison geometry since then.
In $\CBB{}{}$-spaces, it was first used by in  \cite{perelman-petrunin:qg}.
Bit later, independently Jost and Mayer in \cite{jost} and \cite{mayer} 
used the gradient flow in $\cCat{}{}$-spaces; 
this approach has been refined in \cite{grad-flow-book}.
Later, Lytchak in \cite{lytchak:open-map}, 
unified and generalized these two approaches
to a wide class of metric spaces and then it was
yet developed further by Ohta in \cite{ohta} and by Sevar\'e in \cite{sevar'e}.

Gradient flow provides a useful tool in Alexandrov's geometry, 
which we will use everywhere in the book.

This chapter can be divided in two main parts. 
The fist includes sections \ref{sec:grad-def}--\ref{sec:grad-semicont};
it describes ``gradient vector field'' and its properties.
The second includes sections \ref{sec:gradient-like}--\ref{sec:grad-curv:exist};
it describes gradient curves and gradient flow.
In section \ref{sec:non-lip} we describe how to 
modify the proofs so it will work for general semiconcave functions, 
not necessary locally Lipschitz.






























%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Gradient}\label{sec:grad-def}

\begin{thm}{Definition of gradient}\label{def:grad} 
Let $\spc{L}\in\CBB{}{}$, 
$f\:\spc{L}\subto\RR$ be a subfunction
and for a point
$p\in\Dom f$ the differential $\d_p f\:\T_p\to\RR$ is defined.

A tangent vector $g\in \T_p$ is called a 
\emph{gradient of $f$ at $p$}\index{gradient} 
(briefly,  $g=\nabla_p f$\index{$\nabla$}) if
\begin{subthm}{}
$(\d_p f)(w)\le \<g,w\>$ for any $w\in \T_p$, and
\end{subthm}

\begin{subthm}{}
$(\d_p f)(g) = \<g,g\> .$
\end{subthm}
\end{thm}

\begin{thm}{Existence and uniqueness of the gradient}\label{thm:ex-grad} 
Assume $\spc{L}\in\CBB{}{\kappa}$
and $f\:\spc{L}\subto\RR$ be 
locally Lipschitz 
and 
semiconcave subfunction.
Then for any point $p\in \Dom f$, there is unique gradient $\nabla_p f\in \T_p$.
\end{thm}

\parit{Proof; (uniqueness).} 
If $g,g'\in \T_p$ are two gradients of $f$
then 
\begin{align*}
\<g,g\>
&=(\d_p f)(g)\le \<g,g'\>,
&
\<g',g'\>
&=(\d_p f)(g')\le \<g,g'\>.
\end{align*}
Therefore,
\[\dist[2]{g}{g'}{}=\<g,g\>-2\cdot\<g,g'\>+\<g',g'\>=0;\] 
i.e., $g=g'$.

\parit{(Existence).} 
Note first that if $\d_p f\le 0$ then one can take $\nabla_p f=\0$.

Otherwise, if $s=\sup\set{(\d_p f)(\xi)}{\xi\in\Sigma_p}>0$, 
it is sufficient to show that there is  $\overline{\xi}\in \Sigma_p$ such that 
\[
(\d_p f)\l(\overline{\xi}\r)=s.
\eqlbl{overlinexi}
\]
Indeed, if $\overline{\xi}$ exists, then applying Lemma~\ref{lem:ohta} for $u=\overline{\xi}$, $v=\eps\cdot w$ with $\eps\to0+$, 
we get
\[(\d_p f)(w)\le \<w,s\cdot\overline{\xi}\>\] 
for any $w\in\T_p$;
i.e., $s\cdot\overline{\xi}$ is the gradient at $p$.

Take a sequence of directions $\xi_n\in \Sigma_p$, such that $(\d_p f)(\xi_n)\to s$.
Yet once applying Lemma~\ref{lem:ohta} for $u=\xi_n$, $v=\xi_m$, we get
\[s
\ge
\frac{(\d_p f)(\xi_n)+(\d_p f)(\xi_m)}{\sqrt{2+2\cdot\cos\mangle(\xi_n,\xi_m)}}.\]
Therefore $\mangle(\xi_n,\xi_m)\to0$ as $n,m\to\infty$;
i.e., $(\xi_n)$ is a Cauchy sequence.
Clearly $\overline{\xi}=\lim_n\xi_n$ is satisfies \ref{overlinexi}.
\qeds














\section{Calculus of gradient}\label{sec:grad-calculus}



The next lemma roughly states that the gradient points 
in the direction of maximal slope; 
moreover if the slope in the given direction is almost maximal then it is almost direction of the gradient.

\begin{thm}{Lemma}\label{lem:alm-grad}
Let $\spc{L}\in\CBB{}{\kappa}$,
$f\:\spc{L}\subto\RR$ be locally Lipschitz and semiconcave 
and $p\in \Dom f$.

Assume $|\nabla_p f|>0$, 
set $\overline{\xi}=\tfrac{1}{|\nabla_p f|}\cdot\nabla_p f$ then
\begin{subthm}{near-grad} If for $v\in\T_p$, we have $|v|\le 1+\eps$ 
and $(\d_p f)(v) > |\nabla_p f|\cdot(1-\eps)$, then
\[\dist{\overline{\xi}}{v}{}<100\cdot\sqrt{\eps}.\]
\end{subthm}

\begin{subthm}{conv-to-grad} 
If $v_n\in \T_p$ be a sequence of vectors such that 
\[\limsup_{n\to\infty} |v_n|\le 1\ \  
\t{and}\ \  \liminf_{n\to\infty}(\d_p f)(v_n)\ge |\nabla_p f|\] 
then 
\[\lim_{n\to\infty} v_n=\overline{\xi}.\]
\end{subthm}

\begin{subthm}{alm-max} $\overline{\xi}$ is the unique maximum direction for the restriction $\d_p f|_{\Sigma_p}$. 
In particular, 
\[|\nabla_p f|=\sup\set{\d_p f}{\xi\in\Sigma_p f}.\]
\end{subthm}
\end{thm}

\parit{Proof.} According to definition of gradient,
\begin{align*}
 |\nabla_p f|\cdot(1-\eps)
&<
(\d_p f)(v)
\le
\\
&\le\<v,\nabla_p f\>
=
\\
&=
|v|\cdot|\nabla_p f|\cdot\cos\mangle(\nabla_p f,v).
\end{align*}
Thus 
$
|v|>1-\eps$
and
$
\cos\mangle(\nabla_p f,v)>\tfrac{1-\eps}{1+\eps}.
$
Hence  (\ref{SHORT.near-grad}).

Statements (\ref{SHORT.conv-to-grad}) and (\ref{SHORT.alm-max}) follow directly from (\ref{SHORT.near-grad}).
\qeds

As a corollary of the above lemma and Proposition~\ref{prop:conv-comp} we get the following: 

\begin{thm}{Chain rule} %???DO WE NEED IT???
Let $\spc{L}\in\CBB{}{}$, 
$f\:\spc{L}\subto \RR$ be a semiconcave function
and $\phi\:\RR\to\RR$ be a non-decreasing semiconcave function.
Then $\phi\circ f$ is semiconcave and  $\nabla_x(\phi\circ f)=\phi^+(f(x))\cdot\nabla_x f$ for any $x\in\Dom f$.
\end{thm}


The following inequalities describe an important property of the ``gradient
vector field'' which will be used throughout this paper.

\begin{thm}{Lemma} 
\label{lem:grad-lip}
Let $\spc{L}\in\CBB{}{}$, 
$f\:\spc{L}\subto\RR$ satisfies $f''+\kappa\cdot f\le \lambda$ for some $\kappa,\lambda\in\RR$, 
$[p q]\subset \Dom f$ 
and $\ell=\dist{p}{q}{}$.
Then

\begin{wrapfigure}{r}{18mm}
\begin{lpic}[t(0mm),b(0mm),r(0mm),l(5mm)]{pics/grad-lip(0.3)}
\lbl[br]{4,65;$p$}
\lbl[tr]{3,-1;$q$}
\lbl[r]{3,50;$\dir pq$}
%\lbl[tr]{37,9;$\dir qp$}
\lbl[l]{5,30;$\ell$}
\lbl[b]{25,62;$\nabla_p f$}
%\lbl[tl]{55,2;$\nabla_q f$}
\end{lpic}
\end{wrapfigure}

\[\<\dir pq,\nabla_p f\>\ge
\frac
{{f(q)}-{f(p)\cdot\cs\kappa\ell}-\lambda\cdot\md\kappa\ell}
{\sn\kappa\ell}.\]


In particular, 
\begin{subthm}{lem:grad-lip:lam=0}
if $\kappa=0$, 
\[\<\dir pq,\nabla_p f\>\ge
{\l({f(q)}-{f(p)}-\tfrac\lambda2\cdot\ell^2\r)}/{\ell};\]
\end{subthm}

\begin{subthm}{} if $\kappa=1$, $\lambda=0$ we have
\[\<\dir pq,\nabla_p f\>\ge
\l(f(q)-f(p)\cdot\cos\ell\r)/\sin\ell;\]
\end{subthm}

\begin{subthm}{} if $\kappa=-1$, $\lambda=0$ we have
\[\<\dir pq,\nabla_p f\>\ge
\l(f(q)-f(p)\cdot\cosh\ell\r)/\sinh\ell;\]
\end{subthm}
\end{thm}

\parit{Proof of \ref{lem:grad-lip}.} 
Note that 
$\geod_{[p q]}(0)=p$, 
$\geod_{[p q]}(\ell)=q$, 
$(\geod_{[p q]})^+(0)=\dir pq$.
Thus,
\begin{align*}
\<\dir pq,\nabla_p f\>
&\ge 
d_p f(\dir pq)=
\\
&=
(f\circ\geod_{[p q]})^+(0)
\ge
\\
&\ge
\frac
{{f(q)}-{f(p)\cdot\cs\kappa\ell}-\lambda\cdot\md\kappa\ell}
{\sn\kappa\ell}.
\end{align*}
\qedsf

The following corollary states that gradient vector field is monotonic in the sense similar to definition of \emph{monotone operators}; see for example \cite{phelps}.

%???Maybe it is more natural to call this property ``semi-monotonicity or ``$\lambda$-monotonicity'' ???

\begin{thm}{Monotonicity of gradient} 
\label{cor:grad-lip}
Let $\spc{L}\in\CBB{}{\kappa}$, 
$f\:\spc{L}\subto\RR$ be locally Lipschitz and $\lambda$-concave 
and $[p q]\subset \Dom f$.
Then
\[
\<\dir p q,\nabla_p f\>
+
\<\dir q p,\nabla_q f\>
\ge 
-\lambda\cdot\dist[{{}}]{p}{q}{}.
\]

\end{thm}

\parit{Proof.} Add two inequalities from \ref{lem:grad-lip:lam=0}.
\qeds

\begin{thm}{Lemma}\label{lem:close-grad}
Let $\spc{L}\in\CBB{}{\kappa}$, 
$f,g\:\spc{L}\subto\RR$ 
and $p\in\Dom f\cap\Dom g$.

Then 
\[\dist[2]{\nabla_p f}{\nabla_p g}{\T_p}
\le 
(|\nabla_p f|+|\nabla_p g|)
\cdot
\sup\set{|(\d_p f)(\xi)-(\d_p f)(\xi)|}{\xi\in\Sigma_p}.\]

In particular, if $f_n\:\spc{L}\subto\RR$ is a sequence of locally Lipschitz and semiconcave subfunctions,
$p\in \Dom f_n$ for each $n$ 
and $\d_p f_n$ converges uniformly on ${\Sigma_p}$ 
then sequence $\nabla_p f_n\in \T_p$ converges.
\end{thm}

\parit{Proof.}
Set 
\[s
=
\sup
\set{\,|(\d_p f)(\xi)-(\d_p g)(\xi)|}{\xi\in\Sigma_p}.\]
Clearly for any $v\in \T_p$, we have 
\[|(\d_p f)(v)-(\d_p g)(v)|\le s\cdot|v|.\]
From the definition of gradient (\ref{def:grad}) we have:
\begin{align*}
&(\d_p f)(\nabla_p g)\le\<\nabla_p f,\nabla_p g\>,
&&(\d_p g)(\nabla_p f)\le\<\nabla_p f,\nabla_p g\>,
\\
&(\d_p f)(\nabla_p f)=\<\nabla_p f,\nabla_p f\>,
&&(\d_p g)(\nabla_p g)=\<\nabla_p g,\nabla_p g\>.
\end{align*}
Therefore,
\begin{align*}
\dist[{{}}]{\nabla_pf}{\nabla_pg}{}
&=\<\nabla_p f,\nabla_p f\>+\<\nabla_p g,\nabla_p g\>-2\cdot\<\nabla_p f,\nabla_p g\>
\le
\\
&\le (\d_p f)(\nabla_p f)+(\d_p g)(\nabla_p g)-(\d_p f)(\nabla_p g)-(\d_p g)(\nabla_p f)
\le
\\
&\le s\cdot(|\nabla_p f|+|\nabla_p g|).
\end{align*}
\qedsf

The next is a corollary of the above lemma.
It will be used to prove basic properties of tangent space.
Note that the notion of gradient does not appear 
in the formulation.


\begin{thm}{Anti-sum lemma}\label{lem:minus-sum} 
Let $\spc{L}\in\CBB{}{}$ and $p\in \spc{L}$.

Given two vectors $u,v\in \T_p$ there is unique vector $w\in \T_p$ such that
\[\<u,x\>+\<v,x\>+\<w,x\>\ge 0\]
for any $x\in \T_p$ and
\[\<u,w\>+\<v,w\>+\<w,w\>=0.\]

\end{thm}

To obtain the following corollary, applying the above lemma for $u=v$.
In finite-dimensional case, a stronger statement holds, see Milka's lemma (\ref{lem:milka}).

\begin{thm}{Existence of polar vector}\label{cor:polar}
Let $\spc{L}\in\CBB{}{}$ 
and $p\in \spc{L}$. 
Given a vector $u\in \T_p$ there is unique vector $u^*\in\T_p$ such that $\<u^*,u^*\>+\<u,u^*\>= 0$ and
$u^*$ is \emph{polar}\index{polar vector} to $u$;
i.e.,
 $\<u^*,x\>+\<u,x\>\ge 0$ for any $x\in \T_p$.

In particular, for any vector $u\in \T_p$ there is a polar vector $u^*\in\T_p$ such that
$|u^*|\le |u|$.
\end{thm}

\parit{Proof of \ref{lem:minus-sum}.}
Choose two sequences of points $a_n,b_n\in \Str(p)$ such that $\dir{p}{a_n}\to u/|u|$ and $\dir{p}{b_n}\to v/|v|$.
Consider sequence of functions 
\[f_n=|u|\cdot\dist[{{}}]{a_n}{}{}+|v|\cdot\dist[{{}}]{b_n}{}{}.\]
According to Theorem~\ref{thm:d_q dist_p(v)=-<dri p q, v>}, 
\[(\d_pf_n)(x)=-|u|\cdot\<\dir{p}{a_n},x\>-|v|\cdot\<\dir{p}{b_n},x\>.\]
Thus, we have the following uniform convergence for all $x\in\Sigma_p$
\[(\d_pf_n)(x)\xto[n\to\infty]{}-\<u,x\>-\<v,x\>.\] 
According to Lemma~\ref{lem:close-grad}, 
sequence $\nabla_pf_n$ converges.
Set $w=\lim_n\nabla_pf_n$.

From definition of gradient
\[\begin{aligned}
\<w,w\>&=\lim_{n\to\infty}\<\nabla_pf_n,\nabla_pf_n\>=
&&&&&&&&&%right side
\<w,x\>&=\lim_{n\to\infty}\<\nabla_pf_n,x\>\ge
\\%second line
&=\lim_{n\to\infty}(\d_p f_n)(\nabla_p f_n)
=
&&&&&&&&&%second line right side
&\ge
\lim_{n\to\infty}(\d_pf_n)(x)
=
\\%line 3
&=-\<u,w\>-\<v,w\>,
&&&&&&&&&%line 3 right side
&=-\<u,x\>-\<v,x\>.
\end{aligned}\]
\qedsf














\section{Semicontinuity of \textbar gradient\textbar}\label{sec:grad-semicont}

In this section we collect number of corollaries of the following lemma.

\begin{thm}{Ultra limit of \textbar gradient\textbar} \label{lem:gradcon}
Assume
\begin{itemize}
\item $\spc{L}_n\in\CBB{}{\kappa}$ and $(\spc{L}_n,p_n) \to (\spc{L}_\o,p_\o)$ as $n\to\o$;
\item $f_n\:\spc{L}_n\subto \RR$ and $f_\o\:\spc{L}_\o\subto \RR$ are locally Lipschitz and $\lambda$-concave and $f_n\to f_\o$ as $n\to\o$;
\item $x_n\in\Dom f_n$ and $x_n\to x_\o\in \Dom f_\o$ as $n\to\o$.
\end{itemize}
Then 
\[|\nabla_{x_\o} f_\o|
\le 
\lim_{n\to \o} |\nabla_{x_n} f_n|.\]

\end{thm}


\parbf{Remarks.}
To construct an example such that 
$|\nabla_{x_\o} f_\o|
<
\lim_{n\to\o} |\nabla_{x_n} f_n|$;
one can take $\spc{L}_n=\spc{L}_\o=\RR$, $f_n(x)=f_\o(x)=-|x|$ and $x_n\to 0+$.

 From the convergence of gradient curves (proved later in \ref{ultr-lim-g-curve}), 
one can deduce the following slightly stronger statement.
 
\begin{thm}{Proposition}\label{prop:lim|grad|=|grad|}
Assume
\begin{itemize}
\item $\spc{L}_n\in\CBB{}{\kappa}$ and $(\spc{L}_n,p_n) \to (\spc{L}_\o,p_\o)$ as $n\to\o$;
\item $f_n\:\spc{L}_n\subto \RR$ and $f_\o\:\spc{L}_\o\subto \RR$ are locally Lipschitz and $\lambda$-concave and $f_n\to f_\o$ as $n\to\o$.
\end{itemize}
Then 
\[|\nabla_{x_\o} f_\o|
=
\inf \{\lim_{n\to \o} |\nabla_{x_n} f_n|\},\]
where infimum is taken for all sequences $x_n\in\Dom f_n$ such that $x_n\to x_\o\in \Dom f_\o$ as $n\to\o$.
\end{thm}

\parit{Proof of \ref{lem:gradcon}.} 
Fix an $\eps>0$ and choose $y_\o\in \Dom f_\o$ sufficiently close to $x_\o$ such that 
\[|\nabla_{x_\o} f_\o|-\eps<\frac{f_\o(y_\o)-f_\o(x_\o)}{\dist{x_\o}{y_\o}{}}.\]
Choose $y_n\in \spc{L}_n$ such that $y_n\to y_\o$ as $n\to\o$. 
Sinse $\dist{x_\o}{y_\o}{}$ is sufficiently small, the $\lambda$-concavity of $f_n$ implies that
\[ |\nabla_{x_\o} f_\o|-2\cdot\eps
<
(\d_{x_n}f_n)(\dir{x_n}{y_n}),\]
for $\o$-almost all $n$.
Hence,
\[
|\nabla_{x_\o} f_\o|-2\cdot\eps
\le 
\lim_{n\to \o} |\nabla_{x_n} f_n|.\]
Sinse $\eps>0$ is arbitrary, the proposition follows.
\qeds

Note that the distance preserving map $\iota\:\spc{L}\hookrightarrow \spc{L}^\o$ induces an embedding 
\[\d_p\iota\:\T_p \spc{L}\hookrightarrow \T_p \spc{L}^\o.\]
Thus, we can (and will) consider $\T_p \spc{L}$ as a subcone of $\T_p \spc{L}^\o$.

\begin{thm}{Corollary}\label{nablaf=mablaf^o}
Let $\spc{L}\in\CBB{}{}$ 
and $f\:\spc{L}\subto\RR$ be locally Lipschitz semiconcave subfunction.
Then for any point $p\in\Dom f$ we have
\[\nabla_p f=\nabla_p f^\o.\]

\end{thm}

\parit{Proof.} 
Note that $\spc{L}\supset\Dom f\subset \Dom f^\o\subset \spc{L}^\o$. 
Applying \ref{lem:gradcon} for $\spc{L}_n=\spc{L}$ and $x_n=x$, we get $|\nabla_x f|\ge|\nabla_x f^\o|$.

On the other hand, $f=f^\o|\spc{L}$, hence $\d_p f=\d_p f^\o|\T_p \spc{L}$.
Thus, from \ref{alm-max},
$|\nabla_x f|\le|\nabla_x f^\o|$. 
Therefore
\[
|\nabla_x f|=|\nabla_x f^\o|.
\eqlbl{gradfgradultraf}
\]



Further,
\begin{align*}
|\nabla_x f|^2&=(\d_p f)(\nabla_x f)\\
&=\d_pf^\o(\nabla_x f)\le\\ 
&\le\<\nabla_x f^\o,\nabla_x f\>=\\
&=|\nabla_x f^\o|\cdot|\nabla_x f|\cdot\cos\mangle(\nabla_x f^\o,\nabla_x f).
\end{align*}
Together with \ref{gradfgradultraf}, this implies $\mangle(\nabla_x f^\o,\nabla_x f)=0$ and the statement follows.
\qeds

In particular, we have lower-semicontinuity of the function $x\mapsto |\nabla_x f|$:

\begin{thm}{Semicontinuity of \textbar gradient\textbar}\label{cor:gradlim} 
Let $\spc{L}\in\CBB{}{}$ 
and $f\:\spc{L}\subto\RR$ be locally Lipschitz semiconcave subfunction. 
Then the function $x\mapsto|\nabla_x f|$  is lower-continuous;
i.e. for any sequence $x_n\to x\in \Dom f$, we have 
\[|\nabla_x f|\le \liminf_{n\to \infty} |\nabla_{x_n} f|.\]
\end{thm}

\noi\textit{Proof.} 
According to \ref{nablaf=mablaf^o}, $|\nabla_x f|=|\nabla_x f^\o|$. 
Applying \ref{lem:gradcon} for $x_n\to x$, we get that
\[\lim_{n\to\o}|\nabla_{x_n}f|
\ge
|\nabla_x f^\o|
=
|\nabla_x f|.\]
Passing to arbitrary subsequence of $(x_n)$ we obtain the result. \qeds


















\section{Gradient-like curves}\label{sec:gradient-like}


Gradient-like curves provide a technical tool which will be used later in the construction of gradient curves.
The later appear to be a special reparametrization of gradient-like curves.

\begin{thm}{Definition}\label{def:grad-like-curve}
Let $\spc{L}\in \CBB{}{}$
and $f\:\spc{L}\subto\RR$ be locally Lipschitz semiconcave subfunction.

A Lipschitz curve $\hat\alpha\:[s_{\min},s_{\max})\to\Dom f$ will be called \emph{$f$-gradient-like curve} if
\[\hat\alpha^+=\tfrac{1}{|\nabla_{\hat\alpha} f|}\cdot\nabla_{\hat\alpha} f;\]
i.e., for any $s\in[s_{\min},s_{\max})$, $\hat\alpha^+(s)$ is defined and
$\hat\alpha^+(s)=\tfrac{1}{|\nabla_{\hat\alpha(s)} f|}\cdot\nabla_{\hat\alpha(s)} f$.
\end{thm}

Note that in particular this definition implies that $|\nabla_p f|>0$ for any point $p$ on $\hat\alpha$.
The next theorem shows that a weaker condition gives an equivalent definition.

\begin{thm}{Theorem}\label{thm:grad-like-2nd-def}
Let $\spc{L}\in \CBB{}{}$, 
$f\:\spc{L}\subto\RR$ be locally Lipschitz semiconcave subfunction
and 
$|\nabla_p f|>0$ for any $p\in\Dom f$.

A curve $\hat\alpha\:[s_{\min},s_{\max})\to\Dom f$ is an $f$-gradient-like curve if and only if it is $1$-Lipschitz and
\[\liminf_{s\to s_0+}\frac{f\circ\hat\alpha(s)-f\circ\hat\alpha(s_0)}{s-s_0}
\ge 
|\nabla_{\hat\alpha(s_0)} f|
\eqlbl{eq:thm:grad-like-2nd-def-1}\]
for almost all $s_0\in [s_{\min},s_{\max})$.
\end{thm}

\parit{Proof.} The ``only if'' part follows directly from definition.
To prove the ``if'' part, note that for any $s_0\in[s_{\min},s_{\max})$ we have
\begin{align*}
\liminf_{s\to s_0+}\frac{f\circ\hat\alpha(s)-f\circ\hat\alpha(s_0)}{s-s_0}
&\ge 
\liminf_{s\to s_0+}\oint\limits_{s_0}^s|\nabla_{\hat\alpha(\under s)}f|\cdot\d\under s
\ge
\\
&\ge 
|\nabla_{\hat\alpha(s_0)}f|;
\end{align*}
the first inequality follows from \ref{eq:thm:grad-like-2nd-def-1} 
and the second from lower-semicontinuity of function $x\mapsto|\nabla_x f|$, 
see \ref{cor:gradlim}.
Form \ref{lem:alm-grad}, we have 
\[\hat\alpha^+(s_0)=\tfrac{1}{|\nabla_{\hat\alpha(s_0)} f|}\cdot\nabla_{\hat\alpha(s_0)} f;\]
hence the result.
\qeds

%\parbf{Remark of A.} It might have sense to generalize the following theorem to the solutions $f''\le \phi(f,f')$ or at least to the solutions of $f''\le \lambda-\kappa\cdot f$ ???

The following theorem is similar to \cite[2.36]{mayer} and \cite[5.7]{ohta}.

\begin{thm}{Theorem} \label{thm:concave}
Let $\spc{L}\in\CBB{}{}$ 
and
$f\:\spc{L}\subto \RR$ be
locally Lipschitz and $\lambda$-concave. 
Assume $\hat\alpha\:[0,s_{\max})\to\Dom f$ is an $f$-gradient-like curve then 
\[(f\circ\hat\alpha)''\le\lambda\] 
everywhere on $[0,s_{\max})$.
\end{thm} 




\begin{thm}{Corollary}\label{cor:right-cont}
Let $\spc{L}\in\CBB{}{}$,
$f\:\spc{L}\subto \RR$ be a locally Lipschitz and semiconcave function 
and $\hat\alpha\:[0,s_{\max})\to\Dom f$ be an $f$-gradient-like curve.
Then function $s\mapsto |\nabla_{\hat\alpha(s)}f|$
is right-continuous, i.e. for any $s_0\in [0,s_{\max})$ we have
\[|\nabla_{\hat\alpha(s_0)}f|=\lim_{s\to s_0+} |\nabla_{\hat\alpha(s)}f|.\]

\end{thm}

\parit{Proof .} Applying \ref{thm:concave} locally, we have that $f\circ\hat\alpha(s)$ is semiconcave.
The statement follows since 
\[(f\circ\hat\alpha)^+(s)
=
(\d_p f)\l(\tfrac{1}{|\nabla_{\hat\alpha(s)}f|}\cdot\nabla_{\hat\alpha(s)}f\r)
=
|\nabla_{\hat\alpha(s)}f|.\]
\qedsf




\parit{Proof of \ref{thm:concave}.} For any $s>s_0$,
\begin{align*}
(f\circ\hat\alpha)^+(s_0)&=|\nabla_{\hat\alpha(s_0)}f|
\ge
\\
&\ge
(d_{\hat\alpha(s_0)}f)(\dir{\hat\alpha(s_0)}{\hat\alpha(s)})
\ge
\\
&\ge
\frac{f\circ\hat\alpha(s)-f\circ\hat\alpha(s_0)}{\dist{\hat\alpha(s)}{\hat\alpha(s_0)}{}}
-
\tfrac\lambda2\cdot\dist[{{}}]{\hat\alpha(s)}{\hat\alpha(s_0)}{}.
\end{align*}
Set $\lambda_+=\max\{0,\lambda\}$. 
Since $s-s_0\ge\dist{\hat\alpha(s)}{\hat\alpha(s_0)}{}$, for any $s>s_0$ we have 
\[(f\circ\hat\alpha)^+(s_0)\ge
\frac{f\circ\hat\alpha(s)-f\circ\hat\alpha(s_0)}{s-s_0}-\tfrac{\lambda_+}2\cdot(s-s_0).
\eqlbl{eq:thm:concave-1}\]
Thus $f\circ\hat\alpha$ is $\lambda_+$-concave.
That finishes the proof for $\lambda\ge 0$; in case $\lambda<0$ we get only that $f\circ\hat\alpha$ is $0$-concave.

Note that $\dist{\hat\alpha(s)}{\hat\alpha(s_0)}{}=s-s_0-o(s-s_0)$, thus
\[(f\circ\hat\alpha)^+(s_0)\ge
\frac{f\circ\hat\alpha(s)-f\circ\hat\alpha(s_0)}{s-s_0} -\tfrac\lambda2\cdot(s-s_0)+o(s-s_0).
\eqlbl{eq:thm:concave-2}\]
Together, \ref{eq:thm:concave-1} and \ref{eq:thm:concave-2} imply that $f\circ\hat\alpha$ is $\lambda$-concave.
\qeds  




\begin{thm}{Proposition}
\label{prop:grad-like-unique-past}
Let $\spc{L}\in\CBB{}{\kappa}$, $p,q\in\spc{L}$.
Assume $\hat\alpha\:[s_{\min},s_{\max})\to\spc{L}$ be a $\dist{p}{}{}$-gradient-like curve such that $\hat\alpha(s)\to z\in\l]p q\r[$ as $s\to s_{\max}+$
then $\alpha$ is a unit-speed geodesic
which lies in $[p q]$.
\end{thm}

\parit{Proof.} 
Clearly,
\[ \tfrac{d^+}{dt}\dist[{{}}]{q}{\hat\alpha(t)}{}
\ge
-1
\eqlbl{eq:>=-1}
\]
On the other hand,

\[\begin{aligned}
\tfrac{d^+}{dt}\dist[{{}}]{p}{\hat\alpha(t)}{}
&\ge
(\d_{\hat\alpha(t)}\dist{p}{}{})(\dir{\hat\alpha(t)}{q})
\ge\\
&\ge
-\cos\angk\kappa{\hat\alpha(t)}p q.
\end{aligned}
\eqlbl{eq:>=-cos}\]
Inequalities \ref{eq:>=-1} and \ref{eq:>=-cos} imply that the function $t\mapsto\angk\kappa q {\hat\alpha(t)}p $ is non-decreasing.
Hence the result.
\qeds










\section{Gradient curves: Definition}\label{sec:grad-curves:def}

In this section we define gradient curves 
and tie %??? 
them tightly to gradient-like curves 
which were introduced in Section~\ref{sec:gradient-like}.


\begin{thm}{Definition}\label{def:grad-curve}
Let $\spc{L}\in \CBB{}{}$
and $f\:\spc{L}\subto\RR$ be a locally Lipschitz and semiconcave function.

A locally Lipschitz curve $\alpha\:[t_{\min},t_{\max})\to\Dom f$ will be called \emph{$f$-gradient curve} if
\[\alpha^+=\nabla_{\alpha} f;\]
i.e. for any $t\in[t_{\min},t_{\max})$, $\alpha^+(t)$ is defined and 
$\alpha^+(t)=\nabla_{\alpha(t)} f$.
\end{thm}

The next lemma states that gradient and gradient-like curves are special reparametrizations of each-other.

\begin{thm}{Lemma}\label{lem:grad--grad-like}
Let $\spc{L}\in\CBB{}{\kappa}$
and
$f\:\spc{L}\subto\RR$ be a locally Lipschitz semiconcave subfunction 
such that $|\nabla_p f|>0$ for any $p\in\Dom f$.

Assume  $\alpha\:[0,t_{\max})\to \Dom f$ be a locally Lipschitz curve 
and $\hat\alpha\:[0,s_{\max})\to \Dom f$ be its reparametrization by arc-length, 
so $\alpha=\hat\alpha\circ\varsigma$ for some homeomorphism $\varsigma\:[0,t_{\max})\to [0,s_{\max})$,
then 
\[\alpha^+=\nabla_\alpha f
\ \ \ \ \Leftrightarrow\ \ \ \  
\hat\alpha^+=\frac{1}{|\nabla_{\hat\alpha} f|}\cdot\nabla_{\hat\alpha} f\ \ 
\t{and}\ \ 
\varsigma^{-1}(s)
=
\int\limits_0^{s}\frac{\d\under s}{(f\circ\hat\alpha)'(\under s)
 }.\]
\end{thm}

\parit{Proof; $(\Rightarrow)$.} 
According to \ref{thm:speed},
\[\varsigma'(t)\ae|\alpha^+(t)|=|\nabla_{\alpha(t)}f|.
\eqlbl{eq:lem:grad--grad-like-1}\]
Note that 
\[(f\circ\alpha)'(t)\ae (f\circ\alpha)^+(t)=|\nabla_{\alpha(t)} f|^2.\]
Setting $s=\varsigma(t)$, we have
\[(f\circ\hat\alpha)'(s)\ae\frac{(f\circ\alpha)'(t)}{\varsigma'(t)} \ae|\nabla_{\alpha(t)}f|=|\nabla_{\hat\alpha(s)}f|.\]
From \ref{thm:grad-like-2nd-def}, it follows that $\hat\alpha(t)$ is an $f$-gradient-like curve, i.e.
\[\hat\alpha^+=\frac{1}{|\nabla_{\hat\alpha} f|}\cdot\nabla_{\hat\alpha} f.\]
In particular, $(f\circ\hat\alpha)^+(s)=|\nabla_{\hat\alpha^+(s)} f|$ and from \ref{eq:lem:grad--grad-like-1},
\[\varsigma^{-1}(s)=\int\limits_0^{s}\frac{1}{|\nabla_{\hat\alpha(\under s)} f|}\cdot\d\under s
=
\int\limits_0^{s}\frac{1}{(f\circ\hat\alpha)'(\under s)}\cdot\d\under s.\]
\medskip

\noi{$(\Leftarrow)$.}
Clearly,
\[\varsigma(t)
=
\int\limits_0^{t}(f\circ\hat\alpha)^+(\varsigma(\under t))\cdot\d \under t
=
\int\limits_0^{t}|\nabla_{\alpha(\under t)}f|\cdot\d \under t.\]
According to \ref{cor:right-cont}, the function $s\mapsto|\nabla_{\hat\alpha(s)}f|$ is right-continuous.
Therefore the same is true for function $t\mapsto|\nabla_{\hat\alpha\circ\varsigma(t)}f|=|\nabla_{\alpha(t)}f|$.
Hence, for any $t_0\in[0,t_{\max})$ we have
\[\varsigma^+(t_0)
=
\lim_{t\to t_0+}\oint\limits_{t_0}^t|\nabla_{\alpha(\under t)}f|\cdot\d\under t
=
|\nabla_{\alpha(t_0)}f|.\]
Thus, we have 
\[\alpha^+(t_0)
=
\varsigma^+(t_0)\cdot\hat\alpha^+(\varsigma(t_0))
=
\nabla_{\alpha(t_0)} f.\]
\qedsf





















\section{Gradient curves:
distance estimates}\label{sec:grad-curv:dist-est}

%??? ADD ONE MORE ESTIMATE

\begin{thm}{First distance estimate}\label{thm:dist-est}
Let $\spc{L}\in\CBB{}{\kappa}$, 
$f\:\spc{L}\to \RR$ be a locally Lipschitz 
and $\lambda$-concave function.
Assume $\alpha,\beta\:[0,t_{\max})\to \spc{L}$ be two $f$-gradient then for any $t\in[0,t_{\max})$
\[\dist{\alpha(t)}{\beta(t)}{}
\le 
e^{\lambda\cdot t}\cdot\dist[{{}}]{\alpha(0)}{\beta(0)}{}.\]

Moreover, the same conclusion holds for a for locally Lipschitz and $\lambda$-concave subfunction $f\:\spc{L}\subto \RR$ if for any $t\in[0,t_{\max})$ there is a geodesic $[\alpha(t)\,\beta(t)]$ in $\Dom f$.
\end{thm}

\parit{Proof.} 
If $\spc{L}$ is not geodesic space, let us pass to its ultrapower $\spc{L}^\o$.

Fix a choice of geodesic $[\alpha(t)\,\beta(t)]$ for each $t$.

Set $\ell(t)=\dist{\alpha(t)}{\beta(t)}{}$, from the first variation inequality (\ref{lem:first-var}) and the estimate in \ref{cor:grad-lip} we get
\[\ell^+(t)\le-\<\dir{\alpha(t)}{\beta(t)},\nabla_{\alpha(t)}f\>-\<\dir{\beta(t)}{\alpha(t)},\nabla_{\beta(t)}f\>\le \lambda\cdot\ell(t).\]
Hence the result.
\qeds

The following result will not be needed in this chapter, 
it just goes naturally with the previous one.

\begin{thm}{Second distance estimate}\label{lem:fg-dist-est}
Let $\spc{L}\in\CBB{}{\kappa}$, 
$\eps>0$ 
and $f,g\:\spc{L}\to \RR$ be two $\lambda$-concave locally Lipschitz function such that $|f-g|<\eps$.
Assume
$\alpha,\beta\:[0,t_{\max})\to \spc{L}$ are correspondingly $f$- and $g$-gradient curves such that $\alpha(0)=\beta(0)$.
Then 
\[\dist{\alpha(t)}{\beta(t)}{}
\le
\sqrt{\tfrac{1}{2\cdot\eps\cdot\lambda}
\cdot
\l(e^{\frac{t\cdot\lambda}\eps}-1\r)}\]
for any $t\in[0,t_{\max})$.
In particular, if $t_{\max}<\infty$, then
\[\dist{\alpha(t)}{\beta(t)}{}
\le
\Const\cdot\sqrt{\eps\cdot t}\]
for some constant $\Const=\Const(t_{\max},\lambda)$.


Moreover, the same conclusion holds for locally Lipschitz and $\lambda$-concave subfunctions $f,g\:\spc{L}\subto \RR$ if for any $t\in[0,t_{\max})$ there is a geodesic $[\alpha(t)\,\beta(t)]$ in $\Dom f\cap\Dom g$.
\end{thm}

\parit{Proof.} Set $\ell=\ell(t)=\dist{\alpha(t)}{\beta(t)}{}$.
Fix arbitrary fixed $t$, set $p=\alpha(t)$ and $q=\beta(t)$.
From the first variation formula and \ref{lem:grad-lip},
\begin{align*}
 \ell^+
&\le -\<\dir{p}{q},\nabla_{p}f\>
-\<\dir{q}{p},\nabla_{q}g\>
\le
\\
&\le -{\l({f(q)}-{f(p)}-\lambda\cdot\tfrac{\ell^2}2\r)}/{\ell}
-{\l({g(p)}-{g(q)}-\lambda\cdot\tfrac{\ell^2}2\r)}/{\ell}\le
\\
&\le \lambda\cdot\ell+\tfrac{2\cdot\eps}{\ell}
.
\end{align*}
Integrating the above estimate, we get
\[\ell(t)
\le
\sqrt{\tfrac{1}{2\cdot\eps\cdot\lambda}
\cdot\l(e^{\frac{t\cdot\lambda}\eps}-1\r)}.\]
\qedsf




\section{Gradient curves: existence, uniqueness and convergence}
\label{sec:grad-curv:exist}

In general, ``past'' of gradient curves can not be determined by present.
For example, consider concave function $f\:\RR\to\RR$, $f(x)=-|x|$;
two curves $\alpha(t)=\min\{0,t\}$ and $\beta(t)=0$
are $f$-gradient and $\alpha(t)=\beta(t)=0$ for all $t\ge0$, 
however $\alpha(t)\not=\beta(t)$ for all $t<0$.

The next theorem shows that ``future'' gradient curve is unique.

\begin{thm}{Picard's theorem}\label{thm:picard}
Let $\spc{L}\in\CBB{}{}$
and
$f\:\spc{L}\subto \RR$ be semiconcave subfunction.
Assume $\alpha,\beta\:[0,t_{\max})\to\Dom f$ be two $f$-gradient curves 
such that $\alpha(0)=\beta(0)$ then $\alpha(t)=\beta(t)$ for any $t\in[0,t_{\max})$.
\end{thm}

\parit{Proof.} Follows directly from the first distance estimate (\ref{thm:dist-est}).\qeds

\begin{thm}{Local existence}\label{thm:exist-grad-curv}
Let $\spc{L}\in\CBB{}{\kappa}$ 
and $f\:\spc{L}\subto \RR$ be locally Lipschitz $\lambda$-concave subfunction.
Then for any $p\in \Dom f$
\begin{subthm}{}
if $|\nabla_pf|>0$ then for some $\eps>0$, 
there is an $f$-gradient-like curve $\hat\alpha\:[0,\eps)\to\spc{L}$ which starts at $p$ (i.e. $\hat\alpha(0)=p$);
\end{subthm}

\begin{subthm}{}for some $\delta>0$, there is an $f$-gradient curve $\alpha\:[0,\delta)\to \spc{L}$ which starts at $p$ (i.e. $\alpha(0)=p$).
\end{subthm}
\end{thm}

This theorem was proved in \cite{perelman-petrunin:qg};
here we present a simplified proof from \cite{lytchak:open-map}.

\parit{Proof.} 
Note that if $|\nabla_p f|=0$ then one can take constant curve $\alpha(t)=p$.
Otherwise, take $\eps>0$, 
such that $\oBall(p,\eps)\subset\Dom f$,
the restriction $f|_{\oBall(p,\eps)}$ is Lipschitz
and $|\nabla_x f|>\eps$ for all $x\in \oBall(p,\eps)$;
that is possible due to semicontinuity of \textbar gradient\textbar\ (\ref{cor:gradlim}).

The curves $\hat\alpha$ and $\alpha$ will be constructed in the following three steps.
First we construct an $f^\o$-gradient-like curve $\hat\alpha_\o\:[0,\eps)\to\spc{L}^\o$ as an $\o$-limit of certain sequence of broken geodesics in $\spc{L}$.
Second, we parametrize $\hat\alpha_\o$ as in \ref{lem:grad--grad-like}, to obtain an $f^\o$-gradient curve $\alpha_\o$ in $\spc{L}^\o$.
Third, applying Picard's theorem (\ref{thm:picard}) together with Lemma~\ref{lem:X-X^w}, we obtain that $\alpha_\o$ lies in $\spc{L}\subset \spc{L}^\o$ and therefore one can take $\alpha=\alpha_\o$ and $\hat\alpha=\hat\alpha_\o$.

Note that if $\spc{L}$ is proper then $\spc{L}=\spc{L}^\o$ and $f^\o=f$.
Thus, in this case, the third step is not necessary.

\parit{Step 1.}
Given $n\in \NN$, 
by open-close argument,
we can construct a unit-speed curve $\hat\alpha_n\:[0,\eps] \to \spc{L}$ starting at $p$, with a partition of $[0,\eps)$ into countable number of half-open intervals $[\varsigma_i,\bar\varsigma_i)$ 
so that for each $i$ we have 
\begin{enumerate}[(i)]
\item $\hat\alpha_n([\varsigma_i,\bar\varsigma_i])$ is a geodesic and $\bar\varsigma_i-\varsigma_i<\tfrac{1}{n}$.
\item\label{alm-grad} 
$f\circ\hat\alpha_n(\bar\varsigma_i)-f\circ\hat\alpha_n(\varsigma_i)
>
(\bar\varsigma_i-\varsigma_i)
\cdot
(|\nabla_{\hat\alpha_n(\varsigma_i)}f|-\tfrac{1}{n}).$
\end{enumerate}

Pass to a subsequence of $(\hat\alpha_n)$ such that $f\circ\hat\alpha_n$ uniformly converges; set 
\[h(s)=\lim_{n\to\infty}f\circ\hat\alpha_n(s).\]

Set $\hat\alpha_\o=\lim_{n\to\o}\hat\alpha_{n}$, 
it is a curve in $\spc{L}^\o$ 
which starts at $p\in \spc{L}\subset \spc{L}^\o$.

Clearly $\hat\alpha_\o$ is $1$-Lipschitz.
From (\ref{alm-grad}) and \ref{lem:gradcon}, we get \[(f^\o\circ\hat\alpha_\o)^+(\varsigma)\ge|\nabla_{\hat\alpha_\o(\varsigma)}f^\o|.\]
According to \ref{thm:grad-like-2nd-def}, $\hat\alpha_\o\:[0,\eps)\to \spc{L}^\o$  is an $f^\o$-gradient-like curve.

\parit{Step 2.}
Clearly $h(s)=f^\o\circ\alpha_\o$. 
Therefore, according to \ref{thm:concave}, $h$ is $\lambda$-concave.
Thus, we can define a homeomorphism $\varsigma\:[0,\delta]\to[0,\eps]$ by 
\[{\varsigma^{-1}(s)}
=
\int\limits_0^{s}\frac{1}{h'(\under s)}\cdot\d\under s,
\eqlbl{eq:thm:exist-grad-curv-1}\]

According to \ref{lem:grad--grad-like}, $\alpha(t)=\hat\alpha\circ\varsigma(t)$ is an $f^\o$-gradient curve in $\spc{L}^\o$. 

\parit{Step 3.}
Clearly, $\nabla_p f=\nabla_p f^\o$ for any $p\in \spc{L}\subset \spc{L}^\o$;
more formally if $\iota\:\spc{L}\hookrightarrow\spc{L}^\o$ is the natural embedding then
$(\d_p\iota)(\nabla_p f)=\nabla_p f^\o$.
Thus, it is sufficient to show that $\alpha_\o\subset \spc{L}$.
Assume the contrary, then according to \ref{lem:X-X^w} there is a subsequence $\hat\alpha_{n_\kay}$ such that
\[\hat\alpha_\o\not
=
\hat\alpha'_\o
\df
\lim_{\kay\to\o}\hat\alpha_{n_\kay}.\]
Clearly $h(s)=f^\o\circ\hat\alpha_\o=f^\o\circ\hat\alpha'_\o$.
Thus, for $\varsigma\:[0,\delta]\to[0,\eps]$ defined by \ref{eq:thm:exist-grad-curv-1}, 
we have that both curves
$\hat\alpha_\o\circ\varsigma$ and $\hat\alpha'_\o\circ\varsigma$ are $f^\o$-gradient.
Thus, from Picard's theorem (\ref{thm:picard}), we get $\hat\alpha_\o\circ\varsigma=\hat\alpha'_\o\circ\varsigma$ and therefore $\hat\alpha_\o=\hat\alpha'_\o$, a contradiction
\qeds

\begin{thm}{Ultra limit of gradient curves}\label{ultr-lim-g-curve}
Assume
\begin{itemize}
\item $\spc{L}_n\in\CBB{}{\kappa}$ and $(\spc{L}_n,p_n) \to (\spc{L}_\o,p_\o)$ as $n\to\o$;
\item $f_n\:\spc{L}_n\subto \RR$ are $\Lip$-Lipschitz and $\lambda$-concave
$f_n\to f_\o$ as $n\to\o$ and $p_\o\in\Dom f_\o$.
\end{itemize}

Then 

\begin{subthm}{lim-grad-like}
If $|\nabla_{p_\o}f_\o|>0$ then there is $\eps>0$ such that, the $f_n$-gradient-like curves $\hat\alpha_n\:[0,\eps)\to\spc{L}_n$ are defined for $\o$-almost all $n$.
And moreover, a curve $\hat\alpha_\o\:[0,\eps)\to\spc{L}_\o$ is a gradient-like curve which starts at $p_\o$ if and only if
$\hat\alpha_n(s)\to\hat\alpha_\o(s)$ as $n\to\o$ for all $s\in[0,\eps)$.
\end{subthm}

\begin{subthm}{lim-grad}
For some $\delta>0$, the $f_n$-gradient curves $\alpha_n\:[0,\delta)\to\spc{L}_n$ are defined for $\o$-almost all $n$.
And moreover, a curve $\alpha_\o\:[0,\delta)\to\spc{L}_\o$ is a gradient curve which starts at $p_\o$ if and only if
$\alpha_n(t)\to\alpha_\o(t)$  as $n\to\o$ for all $t\in[0,\delta)$.
\end{subthm}
\end{thm}

%??? We need a convergence theorem, which would work for radial curves as well???

The idea in the proof is the same as in the proof of local existence (\ref{thm:exist-grad-curv}).

\parit{Proof.}
According to \ref{thm:convex-limit-cbb}, $f_\o$ is $\lambda$-concave.

\parit{``if''-part of (\ref{SHORT.lim-grad-like}).}
Take $\eps>0$ so small that $\oBall(p_\o,\eps)\subset\Dom f_\o$ and $|\nabla_{x_\o}f_\o|>0$ for any $x_\o\in\oBall(p_\o,\eps)$ (that is possible due to \ref{cor:gradlim}).

Clearly $\hat\alpha_\o$ is $1$-Lipschitz.
From \ref{lem:gradcon}, we get 
$(f_\o\circ\hat\alpha_\o)^+(s)
\ge
|\nabla_{\hat\alpha_\o(s)}f^\o|$.
According to \ref{thm:grad-like-2nd-def}, $\hat\alpha_\o\:[0,\eps)\to \spc{L}^\o$  is an $f_\o$-gradient-like curve.

\parit{``if''-part of (\ref{SHORT.lim-grad}).} Assume first $|\nabla_{p_\o}f_\o|>0$ ---
so we can apply ``if''-part of (\ref{SHORT.lim-grad-like}).
Let $h_n=f_n\circ\hat\alpha_n\:[0,\eps)\to \RR$ 
and $h_\o=f_\o\circ\hat\alpha_\o$.
From \ref{thm:concave}, $h_n$ are $\lambda$-concave and clearly $h_n\to h_\o$ as $n\to\o$.
Let us define reparametrizations
\begin{align*}
{\varsigma_n^{-1}(s)}
&=
\int\limits_0^{s}\frac{1}{h_n'(\under s)}\cdot\d\under s,
&
{\varsigma_\o^{-1}(s)}
&=
\int\limits_0^{s}\frac{1}{h_\o'(\under s)}\cdot\d\under s.
\end{align*}
The $\lambda$-convexity of $h_n$ implies that $\sigma_n\to\sigma_\o$ as $n\to\o$.
By Lemma~\ref{lem:grad--grad-like}, 
$\alpha_n=\hat\alpha_n\circ\varsigma_n$.
Applying ``if''-part of (\ref{SHORT.lim-grad-like}) together with Lemma~\ref{lem:grad--grad-like},
we get that $\alpha_\o=\hat\alpha_\o\circ\varsigma_\o$ is gradient curve.

The remaining case $|\nabla_{p_\o}f_\o|=0$, can be reduced to the one above using the following trick.
Consider sequence of spaces $\spc{L}_n^{\times}=\spc{L}_n\times\RR$,
with the sequence of subfunction $f^{\times}_n\:\spc{L}_n^{\times}\to\RR$, defined by
$f^{\times}_n(p,t)=f_n(p)+t$.
According to Theorem~\ref{thm:cbb-product}, 
$\spc{L}_n^{\times}\in\CBB{}{\kappa_-}$ for $\kappa_-=\min\{\kappa,0\}$
and clearly,
and $f_n^{\times}$ are $\lambda_+$-concave,
for $\lambda_+=\max\{\lambda,0\}$.
Analogously define  $\spc{L}_\o^{\times}=\spc{L}_\o\times\RR$,
and $f^{\times}_\o(p,t)=f_\o(p)+t$.

Clearly 
$\spc{L}_n^{\times}\to\spc{L}_\o^{\times}$,
$f_n^{\times}\to f_\o^{\times}$ as $n\to\o$
and $|\nabla_xf^{\times}_\o|>0$ for any $x\in\Dom f_\o^{\times}$.
Thus, for the sequence $f_n^{\times}\:\spc{L}_n^{\times}\subto\RR$, 
we can apply ``if''-part of (\ref{SHORT.lim-grad-like}).
It is easy to see that $\alpha^{\times}_\o(t)=(\alpha_\o(t),t)$ is a $f^{\times}_\o$-gradient curve in $\spc{L}^{\times}_\o$ 
if and only if $\alpha_\o(t)$ is a $f_\o$-gradient curve.

\parit{``only if''-part of (\ref{SHORT.lim-grad}) and (\ref{SHORT.lim-grad-like}).}
The ``only if''-part of (\ref{SHORT.lim-grad}) follows from
the ``if''-part of (\ref{SHORT.lim-grad}) and Picard's theorem (\ref{thm:picard}).
Applying Lemma~\ref{lem:grad--grad-like}, we get ``only if''-part of (\ref{SHORT.lim-grad-like}).
\qeds

Directly form local existence (\ref{thm:exist-grad-curv}) and distance estimates (\ref{thm:dist-est}), we get the following:

\begin{thm}{Global existence}\label{thm:glob-exist-grad-curv}
Let $\spc{L}\in\CBB{}{\kappa}$ 
and $f\:\spc{L}\subto \RR$ be locally Lipschitz and $\lambda$-concave subfunction.
Then for any $p\in \Dom f$, there is $t_{\max}\in(0,\infty]$ such that
there is an $f$-gradient curve $\alpha\:[0,t_{\max})\to \spc{L}$ with $\alpha(0)=p$.
Moreover, for any sequence $t_n\to t_{\max}-$, the sequence $\alpha(t_n)$ does not have a limit point in $\Dom f$.
\end{thm}

\begin{thm}{Definition}
Let $\spc{L}\in\CBB{}{}$ 
and $f\:\spc{L}\to\RR$ be a semiconcave function.
We say that $f$ has \emph{complete gradient}\index{complete gradient} if for any $x\in\spc{L}$ there is a $f$-gradient curve $\alpha\:[0,\infty)\to\spc{L}$ which starts at $x$;
i.e. $\alpha(0)=x$.
\end{thm}

The following theorem follows from \ref{thm:glob-exist-grad-curv},
\ref{thm:concave} and \ref{lem:grad--grad-like}.

\begin{thm}{Theorem}\label{thm:comp-grad-test}
Let $\spc{L}\in\CBB{}{}$ 
and $f\:\spc{L}\to\RR$ satisfies $f''+\kappa\cdot f\le \lambda$ for some real values $\kappa$ and $\lambda$.
Then $f$ has complete gradient.
\end{thm}

\section{Comments}

The gradient flow for general semiconcave functions 
on smooth Riemannian manifold  can be introduced much cheaper.
To do this note that the distance estimates proved in the Section~\ref{sec:grad-curv:dist-est}
can be proved the same way for gradient curves of smooth semiconcave subfunctions.
By Greene--Wu Lemma (see ???), 
given 
a $\lambda$-concave function $f$, 
a compact set $K\subset \Dom f$
and $\eps>0$
there is a smooth $(\lambda-\eps)$-concave function which is 
$\eps$-close to $f$ in the $C^0$-topology on $K$.
Hence one can apply the smoothing and pass to the limit as $\eps\to0$.
Note that by the second distance estimate the obtained limit curve does not depend on the smoothing.

\section*{Gradient curves for non-Lipschitz functions}\label{sec:non-lip}

\def\LSCSC{\mathrm{LCC}}%???
\def\Wasserstein{\mathrm{P}_2}

In this book, we only consider gradient curves for locally Lipschitz semiconcave subfunctions;
it turns out to be sufficient for all our needs.
However, 
instead of Lipschitz semi-concave subfunctions,
it is more natural to consider upper semi-continuous semi-concave functions
with target in $[-\infty,\infty)$
and to assume in addition that 
the function take finite values at a dense set in the domain of definition.
The set of such subfunctions on a $\CBB{}{}$ space $\spc{L}$ will be denoted as 
$\LSCSC(\spc{L})$ for \textbf{l}ower semi-\textbf{c}ontinous and semi-\textbf{c}oncave.

In this section we describe the adjustments needed
to construct gradient curves in for the subfunctions in $\LSCSC(\spc{L})$.

There is one place where this type of functions appears;
it is the entropy and some other closely related functionals on the Wasserstein space over a $\CBB{}{0}$ space.
The gradient flow for these function play an important role in the theory of optimal transport, see \cite{villani} and references there in. 


\parbf{Differential.} 
First we need to extend the definition of differential (\ref{def:differential}) to $\LSCSC$ subfunctions.

Let $\spc{L}\in\CBB{}{}$ and $f\in\LSCSC(\spc{L})$.
Given a point $p\in \Dom f$, and a geodesic direction $\xi=\dir pq$, 
set 
$\hat \d_pf(\xi)=(f\circ\geod_{[pq]})^+(0)$.
Since $f$ is semiconcave the value $\hat \d_pf(\xi)$ is defined if $f\circ\geod_{[pq]}(t)$ is finite at all sufficiently small values $t>0$,
but $\hat \d_pf(\xi)$ may take value $\infty$. 
Note that $\hat \d_pf$ is defined on a dense subset of $\Sigma_p$.

Set 
\[\d_pf(\zeta)=\limsup_{\xi\to\zeta}\hat\d_pf(\xi)\]
and then set $\d_pf(v)=|v|\cdot \d_pf(\xi)$ if $v=|v|\cdot\xi$ for some $\xi\in\Sigma_p$.

In other words, we define differential as the smallest 
upper semi-continuous  positive-homogeneous function $\d_pf\:\T_p\to\RR$
such that $\d_pf(\xi)\ge \hat \d_pf(\xi)$ if $\hat\d_pf(\xi)$ is defined.



\parbf{Existence and uniqueness of the gradient.}
Note that in the proof of \ref{thm:ex-grad}, 
we used Lipschitz condition just once,
to show that 
\begin{align*}
s&=\sup\set{(\d_p f)(\xi)}{\xi\in\Sigma_p}=
\\
&=\limsup_{x\to p}\frac{f(x)-f(p)}{\dist{x}{p}{}}<
\\
&<\infty.
\end{align*}


The value $s$ above will be denoted as $|\nabla|_pf$.
Note that 
if the gradient $\nabla_pf$ is defined then $|\nabla|_pf=|\nabla_pf|$
and otherwise $|\nabla|_pf=\infty$.

Summarizing the discussion above, 
we get the following.

\parbf{\ref{thm:ex-grad}$'$ Existence and uniqueness of the gradient.}
\textit{Assume $\spc{L}\in\CBB{}{\kappa}$
and $f\in \LSCSC(\spc{L})$. Then for any point $p\in \Dom f$ either 
there is unique gradient $\nabla_p f\in \T_p$ 
or $|\nabla|_pf=\infty$}

\medskip

Further, in all the results of Section~\ref{sec:grad-calculus}, 
we can only assume that $f\in \LSCSC(\spc{L})$ and its gradient is defined at the points in the consideration; 
the proofs are the same.

In sections \ref{sec:grad-semicont}--\ref{sec:grad-curv:exist}
require almost no changes;
mainly, where it is appropriate,
one needs to exchange $|\nabla_p f|$ 
to $|\nabla|_pf$ 
and/or assume that the gradient is defined at the points of interest.
Also one has to take \ref{eq:thm:grad-like-2nd-def-1} in Theorem \ref{thm:grad-like-2nd-def}
as the definition of gradient-like curve.
Then the theorem states that any  gradient-like curve $\alpha\:\II\to\spc{L}$ satisfies the definition \ref{def:grad-like-curve} at $t\in \II$ if $\nabla_{\hat\alpha(s)} f$ is defined.
Further in the Definition \ref{def:grad-curve}, should be changed to the following

\medskip

\parbf{\ref{def:grad-curve}$'$. Definition.}
{\it Let $\spc{L}\in \CBB{}{}$
and $f\in\LSCSC(\spc{L})$.

A curve 
$\alpha\:[t_{\min},t_{\max})\to\Dom f$ will be called \emph{$f$-gradient curve} if
\[\alpha^+(t)=\nabla_{\alpha(t)} f\]
if $\nabla_{\alpha(t)} f$ is defined and 
\[(f\circ\alpha)^+(t)=\infty\]
otherwise.}

\medskip

In the proof of Local existence (\ref{thm:exist-grad-curv}), the condition (\ref{alm-grad})
has to be exchanged to the following condition
\begin{itemize}

\item[{(\ref{alm-grad})}$'$]
$f\circ\hat\alpha_n(\bar\varsigma_i)-f\circ\hat\alpha_n(\varsigma_i)
>
(\bar\varsigma_i-\varsigma_i)
\cdot
\max\{n,|\nabla|_{\hat\alpha_n(\varsigma_i)}f-\tfrac{1}{n})\}.$
\end{itemize}

Any gradient curve $\alpha[0,\ell)\to\spc{L}$
for a subfunction
$f\in \LSCSC(\spc{L})$
satisfy the equation
\[\alpha^+(t)=\nabla_{\alpha(t)} f\]
at all values $t$ with possible exception $t=0$.
In particular, the gradient of $f$ is defined at all points of any 
$f$-gradient curve with the exception for the initial point.



\section{Exercises}

\begin{thm}{Exercise}\label{ex:d dist(grad)<0}
Let $\spc{L}\in\CBB{m}{\kappa}$ and $a,b,p$
are mutually distinct points in $\spc{L}$.
Prove that 
\[(d_p\dist{a}{}{})(\nabla_p\dist{b}{}{})
+\cos\angk\kappa pab\le 0.\]
\end{thm}

\begin{thm}{Exercise}\label{ex:df(v)=<grad f,v>}
Let $\spc{L}\in\CBB{m}{\kappa}$,
the function
$f\:\spc{L}\to\RR$ be semiconcave and locally Lipschitz
and
$\alpha\:\II\to\spc{L}$ be a Lipschitz curve.
Show that 
\[\<\nabla_{\alpha(t)}f,\alpha^+(t)\>
=
(\d_{\alpha(t)}f)(\alpha^+(t))\]
for almost all $t\in\II$.

\end{thm}

\begin{thm}{Exercise}
Let 
$\spc{L}\in\CBB{}{}$ and $f\:\spc{L}\to\RR$ be a concave locally Lipschitz function.
Show that $\alpha\:\RR\to\spc{L}$ is an $f$-gradient curve if and only if
\[\dist[2]{x}{\alpha(t_1)}{\spc{L}}-\dist[2]{x}{\alpha(t_0)}{\spc{L}}
\le 
2\cdot(t_1-t_0)\cdot  (f\circ\alpha(t_1)-f(x))\]
for any $t_1>t_0$ and $x\in\spc{L}$. %???CHECK???
\end{thm}


